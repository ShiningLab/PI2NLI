# PI2NLI - Data

## Directory
The data directory contains the following files:

```
data
├── README.md
├── all.pkl
├── mrpc.pkl
├── parade.pkl
├── paws_qqp.pkl
├── paws_wiki.pkl
├── pit.pkl
└── qqp.pkl
```

## Downloads
You can download the datasets from the Google Drive [PI2NLI Datasets](https://drive.google.com/drive/folders/1Iyj_wLEQKGjOWwnQQHCxEIsU8YCZO8P_?usp=sharing).

## Authors
* **Ning Shi** - mrshininnnnn@gmail.com

## BibTex

```
@inproceedings{dolan-brockett-2005-automatically,
    title = "Automatically Constructing a Corpus of Sentential Paraphrases",
    author = "Dolan, William B.  and
      Brockett, Chris",
    booktitle = "Proceedings of the Third International Workshop on Paraphrasing ({IWP}2005)",
    year = "2005",
    url = "https://aclanthology.org/I05-5002",
}

@inproceedings{xu-etal-2015-semeval,
    title = "{S}em{E}val-2015 Task 1: Paraphrase and Semantic Similarity in {T}witter ({PIT})",
    author = "Xu, Wei  and
      Callison-Burch, Chris  and
      Dolan, Bill",
    booktitle = "Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015)",
    month = jun,
    year = "2015",
    address = "Denver, Colorado",
    Xpublisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S15-2001",
    doi = "10.18653/v1/S15-2001",
    pages = "1--11",
}

@article{iyer2017quora,
  title={Quora question pairs},
  author={Iyer, Shankar and Dandekar, Nikhil and Csernai, Korn{\'e}l},
  journal={First Quora Dataset Release: Question Pairs},
  year={2017}
}

@inproceedings{zhang-etal-2019-paws,
    title = "{PAWS}: Paraphrase Adversaries from Word Scrambling",
    author = "Zhang, Yuan  and
      Baldridge, Jason  and
      He, Luheng",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1131",
    doi = "10.18653/v1/N19-1131",
    pages = "1298--1308",
    abstract = "Existing paraphrase identification datasets lack sentence pairs that have high lexical overlap without being paraphrases. Models trained on such data fail to distinguish pairs like flights from New York to Florida and flights from Florida to New York. This paper introduces PAWS (Paraphrase Adversaries from Word Scrambling), a new dataset with 108,463 well-formed paraphrase and non-paraphrase pairs with high lexical overlap. Challenging pairs are generated by controlled word swapping and back translation, followed by fluency and paraphrase judgments by human raters. State-of-the-art models trained on existing datasets have dismal performance on PAWS ({\textless}40{\%} accuracy); however, including PAWS training data for these models improves their accuracy to 85{\%} while maintaining performance on existing tasks. In contrast, models that do not capture non-local contextual information fail even with PAWS training examples. As such, PAWS provides an effective instrument for driving further progress on models that better exploit structure, context, and pairwise comparisons.",
}

@inproceedings{he-etal-2020-parade,
    title = "{PARADE}: {A} {N}ew {D}ataset for {P}araphrase {I}dentification {R}equiring {C}omputer {S}cience {D}omain {K}nowledge",
    author = "He, Yun  and
      Wang, Zhuoer  and
      Zhang, Yin  and
      Huang, Ruihong  and
      Caverlee, James",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.611",
    doi = "10.18653/v1/2020.emnlp-main.611",
    pages = "7572--7582",
    abstract = "We present a new benchmark dataset called PARADE for paraphrase identification that requires specialized domain knowledge. PARADE contains paraphrases that overlap very little at the lexical and syntactic level but are semantically equivalent based on computer science domain knowledge, as well as non-paraphrases that overlap greatly at the lexical and syntactic level but are not semantically equivalent based on this domain knowledge. Experiments show that both state-of-the-art neural models and non-expert human annotators have poor performance on PARADE. For example, BERT after fine-tuning achieves an F1 score of 0.709, which is much lower than its performance on other paraphrase identification datasets. PARADE can serve as a resource for researchers interested in testing models that incorporate domain knowledge. We make our data and code freely available.",
}
```